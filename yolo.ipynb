{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLASK_URL = \"http://192.168.137.2:4444/receive_docker_output\"\n",
    "CONFIDENCE_MIN = 0.4\n",
    "FIELD_MESSAGE_TYPE = \"message_type\"\n",
    "FIELD_CONTENT = \"content\"\n",
    "FIELD_DATA = \"data\"\n",
    "MST_MSG = \"msg\"\n",
    "CT_SAFETY = \"safety_detection\"\n",
    "MSG_FOREIGN = \"detection_foreign\"\n",
    "\n",
    "RES_START = 1\n",
    "RES_END = 2\n",
    "RES_FOREIGN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\",task=\"detect\")\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(url=str, output=dict):\n",
    "    print(f\"Sending message: {output} to {url}\")\n",
    "    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(output))\n",
    "    response_text = json.loads(response.text)\n",
    "    print(f\"Server response ({url}): {response_text}\")\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(model: YOLO, show=True, url=str):\n",
    "    colors = [(0, 255, 0), (0, 0, 255), (255, 0, 0)]\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    output = {\n",
    "        FIELD_MESSAGE_TYPE: MST_MSG,\n",
    "        FIELD_CONTENT: CT_SAFETY,\n",
    "        FIELD_DATA: {}\n",
    "    }\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        # Read a frame from the video capture\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            output[FIELD_DATA] = {\n",
    "                \"message\": \"No safety camera connected\"\n",
    "            }\n",
    "            break\n",
    "\n",
    "        if counter == 0:\n",
    "            output[FIELD_DATA] = {\n",
    "                \"result\": RES_START,\n",
    "                \"message\": \"Safety detection started\"\n",
    "            }\n",
    "            send_message(url,output)\n",
    "\n",
    "        # Perform inference using the YOLOv8 model\n",
    "        results = model(frame, agnostic_nms=True)[0]\n",
    "\n",
    "        if not results:\n",
    "            continue\n",
    "\n",
    "        for result in results:\n",
    "            detection_count = result.boxes.shape[0]\n",
    "\n",
    "            for i in range(detection_count):\n",
    "                cls = int(result.boxes.cls[i].item())\n",
    "                name = result.names[cls]\n",
    "                confidence = float(result.boxes.conf[i].item())\n",
    "                bounding_box = result.boxes.xyxy[i].cpu().numpy()\n",
    "                if name == \"person\" and confidence > CONFIDENCE_MIN:\n",
    "                    output[FIELD_DATA] = {\n",
    "                        \"result\": RES_FOREIGN,\n",
    "                        \"object\": {\n",
    "                            \"name\": name,\n",
    "                            \"confidence\": confidence\n",
    "                        },\n",
    "                        \"message\": f\"Foreign object detected: {name}, {round(confidence*100,1)}%\"\n",
    "                    }\n",
    "                    \n",
    "                    send_message(url,output)\n",
    "                x = int(bounding_box[0])\n",
    "                y = int(bounding_box[1])\n",
    "                width = int(bounding_box[2] - x)\n",
    "                height = int(bounding_box[3] - y)\n",
    "\n",
    "                if show:\n",
    "                # Draw bounding box and label on the frame\n",
    "                    color = colors[cls % len(colors)]\n",
    "                    label = f'{name}: {confidence:.2f}'\n",
    "                    cv2.rectangle(frame, (x, y), (x + width, y + height), color, 2)\n",
    "                    cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if show:\n",
    "            cv2.imshow('YOLOv8 Detection', frame)\n",
    "\n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    output[FIELD_MESSAGE_TYPE] = MST_MSG\n",
    "    output[FIELD_DATA] = {\n",
    "                \"result\": RES_END,\n",
    "                \"message\": \"Safety detection started\"\n",
    "            }\n",
    "\n",
    "    send_message(url,output)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message: {'message_type': 'msg', 'content': 'safety_detection', 'data': {'result': 1, 'message': 'Safety detection started'}} to http://192.168.137.2:4444/receive_docker_output\n",
      "Server response (http://192.168.137.2:4444/receive_docker_output): {'message': 'Docker output received successfully'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 chair, 1 tv, 1 clock, 1113.6ms\n",
      "Speed: 5.4ms preprocess, 1113.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 1 clock, 1028.9ms\n",
      "Speed: 0.0ms preprocess, 1028.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 clock, 1036.0ms\n",
      "Speed: 0.0ms preprocess, 1036.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 clock, 1025.8ms\n",
      "Speed: 0.0ms preprocess, 1025.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 clock, 1079.3ms\n",
      "Speed: 2.0ms preprocess, 1079.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1067.3ms\n",
      "Speed: 0.0ms preprocess, 1067.3ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1051.0ms\n",
      "Speed: 0.0ms preprocess, 1051.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message: {'message_type': 'msg', 'content': 'safety_detection', 'data': {'result': 0, 'object': {'name': 'person', 'confidence': 0.9445385932922363}, 'message': 'Foreign object detected: person, 0.9445385932922363%'}} to http://192.168.137.2:4444/receive_docker_output\n"
     ]
    }
   ],
   "source": [
    "object_detection(model, False, FLASK_URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
